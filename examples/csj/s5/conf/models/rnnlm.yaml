# topology
lm_type: lstm
n_units: 1024
n_projs: 0
n_layers: 2
emb_dim: 1024
n_units_null_context: 0
tie_embedding: true
residual: true
use_glu: true
# optimization
batch_size: 64
bptt: 200
optimizer: adam
learning_rate: 1e-3
n_epochs: 40
convert_to_sgd_epoch: 40
print_step: 50
decay_start_epoch: 10
decay_rate: 0.9
decay_patient_n_epochs: 0
decay_type: epoch
not_improved_patient_n_epochs: 10
eval_start_epoch: 1
# initialization
param_init: 0.05
# regularization
clip_grad_norm: 1.0
dropout_hidden: 0.5
dropout_out: 0.0
dropout_emb: 0.2
weight_decay: 1e-6
backward: false
adaptive_softmax: false
