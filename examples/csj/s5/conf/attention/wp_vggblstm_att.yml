parent: ./conf/attention/word_blstm_att.yml
param:
  # topology
  conv_in_channel: 1
  conv_channels: [64, 64, 128, 128]
  conv_kernel_sizes:
    - [3, 3]
    - [3, 3]
    - [3, 3]
    - [3, 3]
  conv_strides:
    - [1, 1]
    - [1, 1]
    - [1, 1]
    - [1, 1]
  conv_poolings:
    - []
    - [2, 2]
    - []
    - [2, 2]
  conv_batch_norm: False
  enc_type: blstm
  enc_num_units: 320
  enc_num_projs: 0
  enc_num_layers: 5
  enc_residual: False
  subsample:
    - False
    - False
    - False
    - False
    - False

  # optimization
  batch_size: 25
  print_step: 400

  # initialization
  pretrained_model_path: False

  # MTL
  ctc_weight: 0.0
  bwd_weight: 0.0

  # cold fusion
  cold_fusion: hidden
  rnnlm_cold_fusion: False

  # RNNLM initialization & RNNLM objective
  internal_lm: False
  rnnlm_init: False
  rnnlm_task_weight: 0.0
  share_lm_softmax: False
