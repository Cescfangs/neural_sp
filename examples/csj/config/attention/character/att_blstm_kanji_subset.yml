parent: ../config/attention/word/att_word_freq5_subset_baseline.yml
param:
  # framework
  backend: pytorch
  # backend: chainer

  # corpus
  label_type: kanji
  num_classes: 2888

  # topology
  encoder_num_layers: 4
  subsample_list:
    - False
    - False
    - False
    - False
  embedding_dim: 64

  # optimization
  batch_size: 50
  optimizer: adam
  learning_rate: 1e-3

  # regularization
  scheduled_sampling_ramp_max_step: 250000

  # annealing
  print_step: 500
